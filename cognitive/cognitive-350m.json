{
  "dim": 768,
  "heads": 12,
  "layers": 12,
  "block": 1024,
  "dropout": 0.1,
  "activation": "composed",
  "vocabSize": 32768,
  "tokenizer": "bpe-32k",
  "batch": 4,
  "accumSteps": 8,
  "lr": 3e-4,
  "lrMin": 1e-5,
  "warmupIters": 1000,
  "steps": 30000,
  "gradClip": 1.0,
  "weightDecay": 0.1,
  "packed": true,
  "symbio": false,
  "evalInterval": 500,
  "sampleInterval": 1000,
  "backend": "helios",
  "data": "cognitive/cognitive-v1.txt"
}
